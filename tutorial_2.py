"""
========================================
ç¬¬äºŒå›è¬›ç¾©å®Ÿç¿’ï¼šãƒ‡ãƒ¼ã‚¿å“è³ªã¨AIæ€§èƒ½ã®é–¢ä¿‚
========================================

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä»¥ä¸‹ã‚’å­¦ã³ã¾ã™ï¼š
1. ãƒ‡ãƒ¼ã‚¿ã®ã€Œé‡ã€ãŒAIæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿
2. ãƒ‡ãƒ¼ã‚¿ã®ã€Œè³ªã€ãŒAIæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿
3. "Garbage In, Garbage Out" ã®åŸå‰‡

æ‰€è¦æ™‚é–“ï¼šç´„30-40åˆ†
"""

# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: Google Colabã®å‹•ä½œç¢ºèª
# ============================================
print("=" * 50)
print("ğŸ”§ Google Colabã®ç’°å¢ƒã‚’ç¢ºèªã—ã¾ã™")
print("=" * 50)

import sys

import torch

# Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
print(f"\nğŸ“Œ Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {sys.version.split()[0]}")

# PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
print(f"ğŸ“Œ PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}")

# GPUåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
if torch.cuda.is_available():
    print(f"âœ… GPUåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name(0)}")
    print(
        f"   GPUãƒ¡ãƒ¢ãƒª: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB"
    )
    device = "cuda"
else:
    print("âš ï¸  GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã§å®Ÿè¡Œã—ã¾ã™ã€‚")
    print(
        "   ï¼ˆColabç”»é¢å³ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ > ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ > T4 GPUã‚’é¸æŠã—ã¦ãã ã•ã„ï¼‰"
    )
    device = "cpu"

print("\nç’°å¢ƒç¢ºèªå®Œäº†ï¼æ¬¡ã®ã‚»ãƒ«ã«é€²ã‚“ã§ãã ã•ã„ã€‚\n")

# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# ============================================
print("=" * 50)
print("ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼ˆ1-2åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰")
print("=" * 50)

# PyTorch Lightningã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
#!pip install pytorch-lightning torchmetrics -q

print("âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ï¼\n")

# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ============================================
print("=" * 50)
print("ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã¿ã¾ã™")
print("=" * 50)

import warnings

import matplotlib.pyplot as plt
import numpy as np
import pytorch_lightning as pl
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import japanize_matplotlib

warnings.filterwarnings("ignore")

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆã‚°ãƒ©ãƒ•ç”¨ï¼‰
plt.rcParams["font.sans-serif"] = ["DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False

print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿å®Œäº†ï¼\n")

# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
# ============================================
print("=" * 50)
print("ğŸ–¼ï¸  ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (CIFAR-10) ã‚’æº–å‚™ã—ã¾ã™")
print("=" * 50)
print("\nCIFAR-10ã¨ã¯ï¼š")
print("- 10ç¨®é¡ã®ç‰©ä½“ï¼ˆé£›è¡Œæ©Ÿã€è»Šã€é³¥ã€çŒ«ãªã©ï¼‰ã®å°ã•ãªç”»åƒ")
print("- è¨“ç·´ç”¨: 50,000æšã€ãƒ†ã‚¹ãƒˆç”¨: 10,000æš")
print("- ç”»åƒã‚µã‚¤ã‚º: 32Ã—32ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆã¨ã¦ã‚‚å°ã•ã„ï¼ï¼‰\n")

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆç”»åƒã‚’æ•°å€¤ã«å¤‰æ›ï¼‰
transform = transforms.Compose(
    [
        transforms.ToTensor(),  # ç”»åƒã‚’æ•°å€¤ã®é…åˆ—ã«å¤‰æ›
        transforms.Normalize(
            (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)
        ),  # æ•°å€¤ã‚’-1ã€œ1ã®ç¯„å›²ã«æ­£è¦åŒ–
    ]
)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
print("ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
train_dataset_full = torchvision.datasets.CIFAR10(
    root="./data", train=True, download=True, transform=transform
)
test_dataset = torchvision.datasets.CIFAR10(
    root="./data", train=False, download=True, transform=transform
)

# ã‚¯ãƒ©ã‚¹åï¼ˆç‰©ä½“ã®ç¨®é¡ï¼‰
class_names = ["é£›è¡Œæ©Ÿ", "è»Š", "é³¥", "çŒ«", "é¹¿", "çŠ¬", "è›™", "é¦¬", "èˆ¹", "ãƒˆãƒ©ãƒƒã‚¯"]

print("\nâœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†ï¼")
print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_dataset_full)}æš")
print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æš")

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’è¡¨ç¤º
print("\nğŸ“¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ï¼š")
fig, axes = plt.subplots(2, 5, figsize=(12, 5))
fig.suptitle("CIFAR-10 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ", fontsize=14, fontweight="bold")

for idx, ax in enumerate(axes.flat):
    img, label = train_dataset_full[idx]
    # ç”»åƒã‚’è¡¨ç¤ºç”¨ã«å¤‰æ›ï¼ˆ-1ã€œ1 â†’ 0ã€œ1ï¼‰
    img = img / 2 + 0.5
    ax.imshow(img.permute(1, 2, 0))
    ax.set_title(f"{class_names[label]}", fontsize=10)
    ax.axis("off")

plt.tight_layout()
plt.show()

plt.savefig("cifar10_samples.png")

breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: AIãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
# ============================================
print("=" * 50)
print("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ï¼ˆç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’å®šç¾©ã—ã¾ã™")
print("=" * 50)
print("\nã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ç”»åƒã‚’è¦‹ã¦ã€10ç¨®é¡ã®ç‰©ä½“ã®ã©ã‚Œã‹ã‚’å½“ã¦ã‚‹AIã§ã™ã€‚")
print("äººé–“ã®è„³ã®ç¥çµŒå›è·¯ã‚’æ¨¡å€£ã—ãŸä»•çµ„ã¿ã§å‹•ã„ã¦ã„ã¾ã™ã€‚\n")


class SimpleCNN(pl.LightningModule):
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

    ä»•çµ„ã¿ï¼ˆç°¡å˜ã«ï¼‰ï¼š
    1. ç”»åƒã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒƒã‚¸ã€è‰²ã€å½¢ãªã©ï¼‰
    2. ç‰¹å¾´ã‚’çµ„ã¿åˆã‚ã›ã¦ç‰©ä½“ã‚’èªè­˜
    3. 10ç¨®é¡ã®ã©ã‚Œã‹ã‚’äºˆæ¸¬
    """

    def __init__(self, learning_rate=0.001):
        super().__init__()
        self.save_hyperparameters()

        # ç•³ã¿è¾¼ã¿å±¤ï¼ˆç”»åƒã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡ºï¼‰
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # ç¬¬1å±¤ï¼š32å€‹ã®ç‰¹å¾´ã‚’æŠ½å‡º
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # ç¬¬2å±¤ï¼š64å€‹ã®ç‰¹å¾´ã‚’æŠ½å‡º
        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)  # ç¬¬3å±¤ï¼šã•ã‚‰ã«ç‰¹å¾´ã‚’æ·±æ˜ã‚Š

        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ï¼ˆç”»åƒã‚’å°ã•ãã™ã‚‹ï¼‰
        self.pool = nn.MaxPool2d(2, 2)

        # å…¨çµåˆå±¤ï¼ˆç‰¹å¾´ã‹ã‚‰æœ€çµ‚åˆ¤æ–­ï¼‰
        self.fc1 = nn.Linear(64 * 4 * 4, 64)
        self.fc2 = nn.Linear(64, 10)  # 10ç¨®é¡ã«åˆ†é¡

        # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼ˆéå­¦ç¿’ã‚’é˜²ãï¼‰
        self.dropout = nn.Dropout(0.8)

        # å­¦ç¿’ã®é€²æ—ã‚’è¨˜éŒ²
        self.train_acc_history = []
        self.val_acc_history = []

    def forward(self, x):
        """ç”»åƒã‚’å…¥åŠ›ã—ã¦äºˆæ¸¬ã‚’å‡ºåŠ›"""
        # ç•³ã¿è¾¼ã¿ + æ´»æ€§åŒ– + ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = self.pool(F.relu(self.conv1(x)))  # 32x32 â†’ 16x16
        x = self.pool(F.relu(self.conv2(x)))  # 16x16 â†’ 8x8
        x = self.pool(F.relu(self.conv3(x)))  # 8x8 â†’ 4x4

        # å¹³å¦åŒ–ï¼ˆç”»åƒã‚’1æ¬¡å…ƒã«ï¼‰
        x = x.view(-1, 64 * 4 * 4)

        # å…¨çµåˆå±¤
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

    def training_step(self, batch, batch_idx):
        """è¨“ç·´æ™‚ã®å‡¦ç†"""
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)

        # ç²¾åº¦ã‚’è¨ˆç®—
        acc = (y_hat.argmax(dim=1) == y).float().mean()

        # ãƒ­ã‚°ã«è¨˜éŒ²
        self.log("train_loss", loss, prog_bar=True)
        self.log("train_acc", acc, prog_bar=True)

        return loss

    def validation_step(self, batch, batch_idx):
        """æ¤œè¨¼æ™‚ã®å‡¦ç†"""
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)

        # ç²¾åº¦ã‚’è¨ˆç®—
        acc = (y_hat.argmax(dim=1) == y).float().mean()

        # ãƒ­ã‚°ã«è¨˜éŒ²
        self.log("val_loss", loss, prog_bar=True)
        self.log("val_acc", acc, prog_bar=True)

        return loss

    def configure_optimizers(self):
        """æœ€é©åŒ–æ‰‹æ³•ã®è¨­å®š"""
        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)


breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³6: ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’èª¿æ•´ã™ã‚‹é–¢æ•°
# ============================================
print("=" * 50)
print("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã®ã€Œé‡ã€ã¨ã€Œè³ªã€ã‚’èª¿æ•´ã™ã‚‹æ©Ÿèƒ½ã‚’æº–å‚™ã—ã¾ã™")
print("=" * 50)


def create_dataset_with_quality(
    dataset,
    data_size_ratio: float = 1.0,
    noise_ratio: float = 0.0,
    label_error_ratio: float = 0.0,
    seed: int = 42,
):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é‡ã¨è³ªã‚’èª¿æ•´ã™ã‚‹é–¢æ•°

    å¼•æ•°:
        dataset: å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        data_size_ratio: ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆ0.0ã€œ1.0ï¼‰
            ä¾‹: 0.1 = 10%ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨, 1.0 = å…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
        noise_ratio: ãƒã‚¤ã‚ºã‚’è¿½åŠ ã™ã‚‹å‰²åˆï¼ˆ0.0ã€œ1.0ï¼‰
            ä¾‹: 0.3 = 30%ã®ç”»åƒã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
        label_error_ratio: ãƒ©ãƒ™ãƒ«ã‚’é–“é•ãˆã‚‹å‰²åˆï¼ˆ0.0ã€œ1.0ï¼‰
            ä¾‹: 0.1 = 10%ã®ãƒ©ãƒ™ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´
        seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰

    æˆ»ã‚Šå€¤:
        èª¿æ•´ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    """
    np.random.seed(seed)
    torch.manual_seed(seed)

    # ãƒ‡ãƒ¼ã‚¿é‡ã®èª¿æ•´
    total_size = len(dataset)
    use_size = int(total_size * data_size_ratio)
    indices = np.random.choice(total_size, use_size, replace=False)

    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª¿æ•´:")
    print(f"   - å…ƒã®ã‚µã‚¤ã‚º: {total_size}æš")
    print(f"   - ä½¿ç”¨ã‚µã‚¤ã‚º: {use_size}æš ({data_size_ratio * 100:.0f}%)")
    print(f"   - ãƒã‚¤ã‚ºè¿½åŠ : {noise_ratio * 100:.0f}%ã®ç”»åƒ")
    print(f"   - ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼: {label_error_ratio * 100:.0f}%ã®ãƒ©ãƒ™ãƒ«")

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹
    class QualityAdjustedDataset(Dataset):
        def __init__(self, base_dataset, indices, noise_ratio, label_error_ratio):
            self.base_dataset = base_dataset
            self.indices = indices
            self.noise_ratio = noise_ratio
            self.label_error_ratio = label_error_ratio

        def __len__(self):
            return len(self.indices)

        def __getitem__(self, idx):
            real_idx = self.indices[idx]
            img, label = self.base_dataset[real_idx]

            # ãƒã‚¤ã‚ºã®è¿½åŠ ï¼ˆç”»è³ªã‚’æ‚ªãã™ã‚‹ï¼‰
            if np.random.random() < self.noise_ratio:
                noise = torch.randn_like(img) * 0.5  # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
                img = img + noise
                img = torch.clamp(img, -1, 1)  # ç¯„å›²ã‚’-1ã€œ1ã«åˆ¶é™

            # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼ï¼ˆé–“é•ã£ãŸãƒ©ãƒ™ãƒ«ã‚’ã¤ã‘ã‚‹ï¼‰
            if np.random.random() < self.label_error_ratio:
                label = np.random.randint(0, 10)  # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ©ãƒ™ãƒ«ã«å¤‰æ›´

            return img, label

    adjusted_dataset = QualityAdjustedDataset(
        dataset, indices, noise_ratio, label_error_ratio
    )

    return adjusted_dataset


print("\nâœ… ãƒ‡ãƒ¼ã‚¿èª¿æ•´æ©Ÿèƒ½ã®æº–å‚™å®Œäº†ï¼\n")

breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³7: ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–¢æ•°
# ============================================
print("=" * 50)
print("ğŸ‹ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹é–¢æ•°ã‚’æº–å‚™ã—ã¾ã™")
print("=" * 50)


def train_model(
    train_dataset,
    test_dataset,
    experiment_name: str,
    max_epochs: int = 10,
    batch_size: int = 128,
):
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ç²¾åº¦ã‚’è¿”ã™é–¢æ•°

    å¼•æ•°:
        train_dataset: è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        test_dataset: ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        experiment_name: å®Ÿé¨“åï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ï¼‰
        max_epochs: è¨“ç·´å›æ•°
        batch_size: ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ç”»åƒæ•°

    æˆ»ã‚Šå€¤:
        æœ€çµ‚çš„ãªãƒ†ã‚¹ãƒˆç²¾åº¦
    """

    print(f"\n{'=' * 50}")
    print(f"ğŸš€ å®Ÿé¨“é–‹å§‹: {experiment_name}")
    print(f"{'=' * 50}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,
        persistent_workers=True,
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        persistent_workers=True,
    )

    # ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    model = SimpleCNN()

    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®è¨­å®š
    trainer = pl.Trainer(
        max_epochs=max_epochs,
        accelerator="auto",
        devices=1,
        logger=False,
        enable_checkpointing=False,
        enable_progress_bar=True,
        enable_model_summary=False,
    )

    # è¨“ç·´é–‹å§‹
    print(f"\nâ³ è¨“ç·´ä¸­... (ã‚¨ãƒãƒƒã‚¯æ•°: {max_epochs})")
    trainer.fit(model, train_loader, test_loader)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡
    print("\nğŸ“Š æœ€çµ‚è©•ä¾¡ä¸­...")
    results = trainer.validate(model, test_loader)

    final_accuracy = results[0]["val_acc"]

    print("\nâœ… å®Ÿé¨“å®Œäº†ï¼")
    print(f"   æœ€çµ‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {final_accuracy * 100:.2f}%")

    return final_accuracy


print("\nâœ… è¨“ç·´é–¢æ•°ã®æº–å‚™å®Œäº†ï¼\n")

breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³8: å®Ÿé¨“1 - ãƒ‡ãƒ¼ã‚¿é‡ã®å½±éŸ¿
# ============================================
print("\n" + "=" * 50)
print("ğŸ”¬ å®Ÿé¨“1: ãƒ‡ãƒ¼ã‚¿ã®ã€Œé‡ã€ãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿")
print("=" * 50)
print("\nã€å•ã„ã€‘")
print("ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã¨å¤šã„å ´åˆã§ã€AIã®ç²¾åº¦ã¯ã©ã†å¤‰ã‚ã‚‹ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n")

# å®Ÿé¨“è¨­å®š
data_ratios = [0.05, 0.1, 0.2, 0.5, 1.0]  # 5%, 10%, 20%, 50%, 100%
results_quantity = []

print("ã“ã‚Œã‹ã‚‰5ã¤ã®å®Ÿé¨“ã‚’è¡Œã„ã¾ã™ï¼ˆå„2-3åˆ†ï¼‰:\n")

for ratio in data_ratios:
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ“Œ ãƒ‡ãƒ¼ã‚¿é‡: {ratio * 100:.0f}% ({int(len(train_dataset_full) * ratio)}æš)")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
    train_data = create_dataset_with_quality(
        train_dataset_full,
        data_size_ratio=ratio,
        noise_ratio=0.0,  # ãƒã‚¤ã‚ºãªã—
        label_error_ratio=0.0,  # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼ãªã—
    )

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    accuracy = train_model(
        train_data,
        test_dataset,
        experiment_name=f"ãƒ‡ãƒ¼ã‚¿é‡ {ratio * 100:.0f}%",
        max_epochs=5,  # æ™‚é–“çŸ­ç¸®ã®ãŸã‚5ã‚¨ãƒãƒƒã‚¯
        batch_size=128,
    )

    results_quantity.append({"ratio": ratio, "accuracy": accuracy})

# çµæœã®å¯è¦–åŒ–
print("\n" + "=" * 50)
print("ğŸ“ˆ å®Ÿé¨“1ã®çµæœã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º")
print("=" * 50)

plt.figure(figsize=(10, 6))
ratios = [r["ratio"] * 100 for r in results_quantity]
accuracies = [r["accuracy"] * 100 for r in results_quantity]

plt.plot(ratios, accuracies, marker="o", linewidth=2, markersize=10, color="#2E86AB")
plt.xlabel("ãƒ‡ãƒ¼ã‚¿é‡ (%)", fontsize=12, fontweight="bold")
plt.ylabel("ãƒ†ã‚¹ãƒˆç²¾åº¦ (%)", fontsize=12, fontweight="bold")
plt.title("å®Ÿé¨“1: ãƒ‡ãƒ¼ã‚¿é‡ã¨AIç²¾åº¦ã®é–¢ä¿‚", fontsize=14, fontweight="bold")
plt.grid(True, alpha=0.3)
plt.xticks(ratios)

# å„ç‚¹ã«å€¤ã‚’è¡¨ç¤º
for ratio, acc in zip(ratios, accuracies):
    plt.annotate(
        f"{acc:.1f}%",
        xy=(ratio, acc),
        xytext=(0, 10),
        textcoords="offset points",
        ha="center",
        fontsize=10,
        fontweight="bold",
    )

plt.tight_layout()
plt.savefig("data_quantity_vs_accuracy.png")
plt.show()

print("\nğŸ’¡ è€ƒå¯Ÿãƒã‚¤ãƒ³ãƒˆ:")
print("   - ãƒ‡ãƒ¼ã‚¿é‡ãŒå¢—ãˆã‚‹ã¨ç²¾åº¦ã¯ä¸ŠãŒã‚Šã¾ã—ãŸã‹ï¼Ÿ")
print("   - ã©ã®ãã‚‰ã„ã®ãƒ‡ãƒ¼ã‚¿é‡ã‹ã‚‰ç²¾åº¦ãŒå®‰å®šã—ã¾ã™ã‹ï¼Ÿ")
print("   - å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®Ÿç”¨çš„ãªç²¾åº¦ã¯å¾—ã‚‰ã‚Œã¾ã—ãŸã‹ï¼Ÿ\n")


breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³9: å®Ÿé¨“2 - ãƒ‡ãƒ¼ã‚¿å“è³ªã®å½±éŸ¿
# ============================================
print("\n" + "=" * 50)
print("ğŸ”¬ å®Ÿé¨“2: ãƒ‡ãƒ¼ã‚¿ã®ã€Œè³ªã€ãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿")
print("=" * 50)
print("\nã€å•ã„ã€‘")
print("ãƒ‡ãƒ¼ã‚¿ã«ãƒã‚¤ã‚ºã‚„ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã€AIã®ç²¾åº¦ã¯ã©ã†å¤‰ã‚ã‚‹ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n")

# å®Ÿé¨“è¨­å®š
quality_settings = [
    {"noise": 0.0, "label_error": 0.0, "name": "å®Œç’§ãªãƒ‡ãƒ¼ã‚¿"},
    {"noise": 0.3, "label_error": 0.0, "name": "ãƒã‚¤ã‚º30%"},
    {"noise": 0.0, "label_error": 0.1, "name": "ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼10%"},
    {"noise": 0.3, "label_error": 0.1, "name": "ãƒã‚¤ã‚º30% + ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼10%"},
]

results_quality = []

print("ã“ã‚Œã‹ã‚‰4ã¤ã®å®Ÿé¨“ã‚’è¡Œã„ã¾ã™ï¼ˆå„2-3åˆ†ï¼‰:\n")

for setting in quality_settings:
    print(f"\n{'â”€' * 50}")
    print(f"ğŸ“Œ å®Ÿé¨“: {setting['name']}")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    train_data = create_dataset_with_quality(
        train_dataset_full,
        data_size_ratio=0.2,  # æ™‚é–“çŸ­ç¸®ã®ãŸã‚20%ä½¿ç”¨
        noise_ratio=setting["noise"],
        label_error_ratio=setting["label_error"],
    )

    # å“è³ªãŒæ‚ªã„ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºï¼ˆæœ€åˆã®å®Ÿé¨“ã®ã¿ï¼‰
    if setting["noise"] > 0 or setting["label_error"] > 0:
        if results_quality == []:  # æœ€åˆã®æ‚ªã„ãƒ‡ãƒ¼ã‚¿ã®å®Ÿé¨“æ™‚ã®ã¿
            print("\nğŸ“¸ å“è³ªã®æ‚ªã„ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«:")
            fig, axes = plt.subplots(1, 5, figsize=(12, 3))
            fig.suptitle(
                f"{setting['name']} ã®ã‚µãƒ³ãƒ—ãƒ«", fontsize=12, fontweight="bold"
            )

            for idx, ax in enumerate(axes):
                img, label = train_data[idx]
                img = img / 2 + 0.5  # è¡¨ç¤ºç”¨ã«æ­£è¦åŒ–
                img = torch.clamp(img, 0, 1)  # ç¯„å›²ã‚’0-1ã«åˆ¶é™
                ax.imshow(img.permute(1, 2, 0))
                ax.set_title(f"{class_names[label]}", fontsize=9)
                ax.axis("off")

            plt.tight_layout()
            plt.show()

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    accuracy = train_model(
        train_data,
        test_dataset,
        experiment_name=setting["name"],
        max_epochs=5,
        batch_size=128,
    )

    results_quality.append(
        {
            "name": setting["name"],
            "noise": setting["noise"],
            "label_error": setting["label_error"],
            "accuracy": accuracy,
        }
    )

# çµæœã®å¯è¦–åŒ–
print("\n" + "=" * 50)
print("ğŸ“ˆ å®Ÿé¨“2ã®çµæœã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º")
print("=" * 50)

plt.figure(figsize=(12, 6))
names = [r["name"] for r in results_quality]
accuracies = [r["accuracy"] * 100 for r in results_quality]
colors = ["#06D6A0", "#FFD166", "#EF476F", "#AB0011"]

bars = plt.bar(names, accuracies, color=colors, edgecolor="black", linewidth=1.5)
plt.ylabel("ãƒ†ã‚¹ãƒˆç²¾åº¦ (%)", fontsize=12, fontweight="bold")
plt.title("å®Ÿé¨“2: ãƒ‡ãƒ¼ã‚¿å“è³ªã¨AIç²¾åº¦ã®é–¢ä¿‚", fontsize=14, fontweight="bold")
plt.ylim(0, 100)
plt.grid(True, axis="y", alpha=0.3)

# å„ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
for bar, acc in zip(bars, accuracies):
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2.0,
        height + 1,
        f"{acc:.1f}%",
        ha="center",
        va="bottom",
        fontsize=11,
        fontweight="bold",
    )

plt.xticks(rotation=15, ha="right")
plt.tight_layout()
plt.savefig("data_quality_vs_accuracy.png")
plt.show()

print("\nğŸ’¡ è€ƒå¯Ÿãƒã‚¤ãƒ³ãƒˆ:")
print("   - ãƒã‚¤ã‚ºãŒã‚ã‚‹ã¨ç²¾åº¦ã¯ã©ã®ãã‚‰ã„ä¸‹ãŒã‚Šã¾ã—ãŸã‹ï¼Ÿ")
print("   - ãƒ©ãƒ™ãƒ«ã‚¨ãƒ©ãƒ¼ã®å½±éŸ¿ã¯å¤§ãã„ã§ã™ã‹ï¼Ÿ")
print("   - è¤‡æ•°ã®å•é¡ŒãŒçµ„ã¿åˆã‚ã•ã‚‹ã¨ã©ã†ãªã‚Šã¾ã™ã‹ï¼Ÿ\n")

breakpoint()


# ============================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³10: ç·åˆçµæœã¨ã¾ã¨ã‚
# ============================================
print("\n" + "=" * 50)
print("ğŸ“‹ å®Ÿé¨“çµæœã®ã¾ã¨ã‚")
print("=" * 50)

print("\nã€å®Ÿé¨“1: ãƒ‡ãƒ¼ã‚¿é‡ã®å½±éŸ¿ã€‘")
print("-" * 50)
for r in results_quantity:
    print(f"  ãƒ‡ãƒ¼ã‚¿é‡ {r['ratio'] * 100:>5.0f}% â†’ ç²¾åº¦ {r['accuracy'] * 100:>5.2f}%")

print("\nã€å®Ÿé¨“2: ãƒ‡ãƒ¼ã‚¿å“è³ªã®å½±éŸ¿ã€‘")
print("-" * 50)
for r in results_quality:
    print(f"  {r['name']:<30} â†’ ç²¾åº¦ {r['accuracy'] * 100:>5.2f}%")

# æœ€è‰¯ã¨æœ€æ‚ªã®æ¯”è¼ƒ
best_quality = max(results_quality, key=lambda x: x["accuracy"])
worst_quality = min(results_quality, key=lambda x: x["accuracy"])

print("\n" + "=" * 50)
print("ğŸ¯ é‡è¦ãªç™ºè¦‹")
print("=" * 50)

print("\n1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿é‡ã®å½±éŸ¿:")
print(f"   - æœ€å°ãƒ‡ãƒ¼ã‚¿(5%): {results_quantity[0]['accuracy'] * 100:.1f}%")
print(f"   - æœ€å¤§ãƒ‡ãƒ¼ã‚¿(100%): {results_quantity[-1]['accuracy'] * 100:.1f}%")
print(
    f"   - å·®: {(results_quantity[-1]['accuracy'] - results_quantity[0]['accuracy']) * 100:.1f}ãƒã‚¤ãƒ³ãƒˆ"
)

print("\n2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿å“è³ªã®å½±éŸ¿:")
print(f"   - æœ€è‰¯({best_quality['name']}): {best_quality['accuracy'] * 100:.1f}%")
print(f"   - æœ€æ‚ª({worst_quality['name']}): {worst_quality['accuracy'] * 100:.1f}%")
print(
    f"   - å·®: {(best_quality['accuracy'] - worst_quality['accuracy']) * 100:.1f}ãƒã‚¤ãƒ³ãƒˆ"
)

print("\n" + "=" * 50)
print("ğŸ’¡ ã€ŒGarbage In, Garbage Outã€ã®åŸå‰‡")
print("=" * 50)
print("""
ä»Šæ—¥ã®å®Ÿé¨“ã‹ã‚‰å­¦ã‚“ã ã“ã¨:

âœ… ãƒ‡ãƒ¼ã‚¿ã®ã€Œé‡ã€ã¯é‡è¦
   â†’ ã§ã‚‚ã€ã‚ã‚‹ç¨‹åº¦ä»¥ä¸Šã‚ã‚Œã°åŠ¹æœã¯é ­æ‰“ã¡

âœ… ãƒ‡ãƒ¼ã‚¿ã®ã€Œè³ªã€ã¯éå¸¸ã«é‡è¦
   â†’ ãƒã‚¤ã‚ºã‚„ã‚¨ãƒ©ãƒ¼ã¯ç²¾åº¦ã‚’å¤§ããä¸‹ã’ã‚‹

âœ… ã©ã‚“ãªã«å„ªã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã§ã‚‚...
   â†’ æ‚ªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯è‰¯ã„çµæœã¯ç”Ÿã¾ã‚Œãªã„

ğŸ“Œ çµè«–:
   AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æœ€ã‚‚é‡è¦ãªã®ã¯ã€
   ã€Œè‰¯è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’é›†ã‚ã‚‹ã“ã¨ã€

   ãƒ¢ãƒ‡ãƒ«ã®æ”¹è‰¯ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®æ”¹å–„ãŒå…ˆï¼
""")

print("\n" + "=" * 50)
print("ğŸ“ å®Ÿç¿’å®Œäº†ï¼ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
print("=" * 50)
print("\næ¬¡å›ã®è¬›ç¾©ã§ã¯ã€çµ±è¨ˆçš„æ€è€ƒã®åŸºç¤ã‚’å­¦ã³ã¾ã™ã€‚")
print("ä»Šæ—¥å­¦ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®é‡è¦æ€§ã‚’å¿˜ã‚Œãšã«ï¼\n")
